{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:32px; font-weight: bolder; text-align: center\"> Molecular dynamics and sampling </p>\n",
    "<p style=\"text-align: center\"><i> authored by: <a href=\"mailto:michele.ceriotti@gmail.com\"> Michele Ceriotti </a></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a hands-on counterpart to the \"Molecular dynamics and sampling\" lecture for the MOOC \"Path Integrals in Atomistic Modeling\". If you haven't done so already, check the [getting started](0-getting_started.ipynb) notebook to make sure that the software infrastructure is up and running. \n",
    "\n",
    "The different sections in this notebook match the parts this lecture is divided into:\n",
    "\n",
    "1. [Thermodynamics and phase-space sampling](#thermo-and-sampling)\n",
    "2. [Molecular dynamics and integrators](#integrators)\n",
    "3. [Efficiency of sampling](#sampling-efficiency)\n",
    "4. [Langevin dynamics](#langevin)\n",
    "\n",
    "<p style=\"color:blue; font-weight:bold\"> Questions in blue invite you to reflect on the results you are obtaining. If you are doing these notebooks as part of a course, there might be questions to answer relative to those parts. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ase, ase.io\n",
    "import chemiscope\n",
    "import pimdmooc\n",
    "pimdmooc.add_ipi_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"thermo-and-sampling\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thermodynamics and phase-space sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider a (classical) harmonic oscillator with frequency $\\omega$ and unit mass, in the constant-temperature ensemble at inverse temperature $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pot_sho(q, omega=1):\n",
    "    \"\"\" The potential for a simple harmonic oscillator with frequency omega and unit mass\"\"\"\n",
    "    return omega**2*q**2/2\n",
    "def kin_sho(p):\n",
    "    \"\"\" The kinetic energy for a particle with unit mass\"\"\"\n",
    "    return p**2/2\n",
    "def ham_sho(p, q, omega=1):\n",
    "    \"\"\" The Hamiltonian for the simple harmonic oscillator \"\"\"\n",
    "    return kin_sho(p) + pot_sho(q, omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: beta=1; omega0=2\n",
    "beta = 1\n",
    "omega0 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration on a grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute the partition function and observables using explicit integration on a grid - using the simplest rectangle integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: ngrid=16\n",
    "ngrid = 16\n",
    "\n",
    "pgrid = np.linspace(-10,10,ngrid)\n",
    "dp = pgrid[1]-pgrid[0]\n",
    "\n",
    "qgrid = np.linspace(-10,10,ngrid)\n",
    "dq = qgrid[1]-qgrid[0]\n",
    "\n",
    "pqgrid = np.meshgrid(pgrid, qgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_grid = ham_sho(pqgrid[0], pqgrid[1], omega=omega0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partition function is just \n",
    "\n",
    "$$\n",
    "Z=\\int \\mathrm{d}q\\mathrm{d}p e^{-\\beta(V(q)+K(p))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.exp(-ham_grid*beta).sum()*dp*dq\n",
    "print(\"Partition function, Z: \", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note that the _classical_ partition function (and the probability) can be factorized into a $q$ and $p$ dependent parts, $Z=Z_qZ_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_grid = pot_sho(qgrid, omega=omega0)\n",
    "kin_grid = kin_sho(pgrid)\n",
    "Zp = np.exp(-kin_grid*beta).sum()*dp\n",
    "Zq = np.exp(-pot_grid*beta).sum()*dq\n",
    "Z - Zp*Zq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean potential and kinetic energy can be computed as a weighted mean, and again one can equally well compute it on just the relevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_mean = (pot_sho(pqgrid[1], omega=omega0)* np.exp(-ham_grid*beta)).sum()*dp*dq/Z\n",
    "print(\"Average potential, <V>: \", pot_mean)\n",
    "\n",
    "kin_mean = (kin_sho(pqgrid[0])* np.exp(-ham_grid*beta)).sum()*dp*dq/Z\n",
    "print(\"Average kinetic, <K>:   \", kin_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle V \\rangle = \\frac{1}{Z_q} \\int \\mathrm{d}q V(q) e^{-\\beta V(q)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_mean_q = (pot_grid*np.exp(-pot_sho(qgrid, omega=omega0)*beta)).sum()*dq/Zq\n",
    "pot_mean - pot_mean_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\langle K \\rangle = \\frac{1}{Z_p} \\int \\mathrm{d}p \\frac{p^2}{2m} e^{-\\beta K(p)} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kin_mean_p = (kin_grid*np.exp(-kin_sho(pgrid)*beta)).sum()*dp/Zp\n",
    "kin_mean - kin_mean_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\"> What is the expected value of $Z$, $\\langle V \\rangle$, $\\langle K \\rangle$? Experiment with different `ngrid` parameters. How many grid points you need to converge the values to roughly 1%. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naively, we can generate uniform random samples over a large interval, and compute the average by Monte Carlo integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: nmc=1000\n",
    "nmc = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmc = np.random.uniform(-10,10,size=(nmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_mc = pot_sho(qmc, omega=omega0)\n",
    "prob_mc = np.exp(-pot_mc * beta)\n",
    "pot_mean = (prob_mc*pot_mc).mean() / prob_mc.mean()\n",
    "print(\"Average potential: \", pot_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the samples are \"wasted\" over low-probability regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(prob_mc, bins=100)\n",
    "plt.xlabel(\"weight\"); plt.ylabel(\"counts\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">Repeat the calculation with different numbers of random samples, to get a feeling for the statistical uncertainty and the convergence behavior. What would happen if you reduced the range of the grid to a narrower region around $0$?</p>\n",
    "\n",
    "You could also rather easily wrap the generation and evaluation in a function to compute more quantitatively the uncertainty over multiple executions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid wasting samples on low-probability regions, we can generate a sequence of configurations that are distributed according to the target probability. \n",
    "This uses a Metropolis Monte Carlo scheme, which is not explained in the course. The [original publication](http://doi.org//10.1063/1.1699114) is a classic, and very accessible.\n",
    "\n",
    "In short, the algorithm works by first _proposing_ a change to the configuration, in a way that is symmetric $u(q_0 \\rightarrow q_1) = u(q_1\\rightarrow q_0)$. Here we take a random step between $-\\Delta q$ and $\\Delta q$. \n",
    "\n",
    "The probabilities in the initial and final state are then compared, and an _acceptance_ criterion is applied to actually update the position, or to keep the system in $q_0$. The overall probability of making a move is the product of the proposal and acceptance probabilities, $p(q_0\\rightarrow q_1) = u(q_0\\rightarrow q_1) a(q_0\\rightarrow q_1)$.\n",
    "The criterion is designed so satisfy the detailed-balance condition $P(q_0) p(q_0\\rightarrow q_1) = P(q_1) p(q_1\\rightarrow q_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_step(q0, step=1):\n",
    "    \"\"\"\"Performs one step in a Monte Carlo procedure, following the Metropolis scheme, cf.\n",
    "    N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller, \n",
    "    \"Equation of State Calculations by Fast Computing Machines,\" \n",
    "    Journal of Chemical Physics 21(6), 1087–1092 (1953).\n",
    "    \"\"\"\n",
    "    \n",
    "    # NB: this implementation recomputes the potential at each step, which is \n",
    "    # very wasteful - potential could be stored and reused between steps\n",
    "    pot0 = pot_sho(q0, omega=omega0)\n",
    "    \n",
    "    # generates a random displacement (with symmetric probability)\n",
    "    q1 = q0 + np.random.uniform(-1,1)*step\n",
    "        \n",
    "    pot1 = pot_sho(q1, omega=omega0)\n",
    "    \n",
    "    # computes the ratio of initial and final probabilities        \n",
    "    pratio = np.exp((pot0-pot1)*beta)\n",
    "    \n",
    "    # accepts or rejects the move to enforce a detailed balance condition\n",
    "    if (pratio > np.random.uniform(0,1)):\n",
    "        return q1\n",
    "    else:\n",
    "        return q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: q=0, nstep=1000, mcstep=1\n",
    "q = 0\n",
    "nstep = 1000\n",
    "mcstep = 1\n",
    "\n",
    "traj_q = np.zeros(nstep)\n",
    "for i in range(nstep):    \n",
    "    q = metropolis_step(q, step=mcstep)\n",
    "    traj_q[i] = q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The position fluctuates around equilibrium, and is distributed according to $P(q)$. Note that strictly speaking one should discard the first few steps as they are needed to reach equilibrium.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(traj_q)\n",
    "plt.xlabel(\"step\"); plt.ylabel(\"q / a.u.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(traj_q[10:], bins=100)\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel(\"counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_mean = pot_sho(traj_q, omega = omega0).mean()\n",
    "print(\"Average potential: \", pot_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Change the magnitude of the step (variable `mcstep`) to 0.01 and to 100. \n",
    "What consideration can you make on the efficiency of the probability sampling process?\n",
    "</p>\n",
    "\n",
    "This topic will be investigated further in [section 3](#sampling-efficiency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"integrators\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Molecular dynamics and integrators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section requires use of i-PI, so make sure you have it installed and have familiarized yourself with how to run it in the [getting started](0-getting_started.ipynb) section. \n",
    "\n",
    "Here we will modify an existing i-PI input to run constant-energy simulations for a small simulation of liquid water, based on the q-TIP4P/f forcefield ([original paper](http://doi.org/10.1063/1.3167790)), run short trajectories and inspect the output.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first go to the appropriate folder, create a copy of the template and edit it.  You will need to open a terminal and execute\n",
    "\n",
    "```\n",
    "$ cd pimd-mooc/1-md_sampling\n",
    "$ cp template_integrator.xml input.xml\n",
    "```\n",
    "\n",
    "Edit the `input.xml` file. You can use `vi` in the terminal, or open the file with the file editing interface of Jupyter/Jupyterlab. \n",
    "\n",
    "First, we are going to set up a rather \"by the book\" simulation - a conservative time step for liquid water is of the order of 0.5 fs. Look for the time step specification and edit it so it reads `<timestep units='femtosecond'> 0.5 </timestep>`. You should also set the output prefix to a memorable name - it is recommended to use `<output prefix='md-ts_0.5'>` to be compatible with the postprocessing in this notebook.\n",
    "\n",
    "Then launch i-PI and the driver - either using two terminals or putting i-PI in the background (wait a second or two before launching the driver, to make sure that the server has started and opened the socket)\n",
    "\n",
    "```\n",
    "$ i-pi input.xml &\n",
    "$ i-pi-driver -u -h driver -m qtip4pf \n",
    "```\n",
    "\n",
    "_NB: the simulation will take a few minutes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the simulation is finished, we can load the output and plot it. One sees how potential and kinetic energy fluctuate wildly (over an energy scale of a significant fraction of a Hartree, while "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_05 = pimdmooc.read_ipi_output('1-md_sampling/md-ts_0.5.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_05[\"time\"], ts_05[\"potential\"], label=\"V\")\n",
    "plt.plot(ts_05[\"time\"], ts_05[\"conserved\"], label=\"H\")\n",
    "plt.plot(ts_05[\"time\"], ts_05[\"kinetic_md\"], label=\"K\")\n",
    "plt.xlabel(\"time / ps\"); plt.ylabel(\"energy / a.u.\"); \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modify `input.xml` to run a simulation with timestep of 1.0 fs, 1.5 fs and 2.0 fs, running each time a separate simulation; make sure to also change the output `prefix` accordingly - use e.g. `'md-ts_2.0'` as format, or adjust the plotting cells below to reflect your naming scheme. \n",
    "\n",
    "_NB: Depending on the speed of the system you are running this on, each simulation may take less than a minute, or several minutes. If you do not want to wait for each calculation to be finished before launching another one, you will need to open multiple terminals, and give different names to each of the sockets, changing both the `<address>` field in the xml input, and the `-h` option in the driver._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the simulations, we can inspect the behavior of the conserved quantity to check for the accuracy of integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_10 = pimdmooc.read_ipi_output('1-md_sampling/md-ts_1.0.out')\n",
    "ts_15 = pimdmooc.read_ipi_output('1-md_sampling/md-ts_1.5.out')\n",
    "ts_20 = pimdmooc.read_ipi_output('1-md_sampling/md-ts_2.0.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts_20[\"time\"], ts_20[\"conserved\"], label=r\"$\\Delta t = 2.0$ fs\")\n",
    "plt.plot(ts_15[\"time\"], ts_15[\"conserved\"], label=r\"$\\Delta t = 1.5$ fs\")\n",
    "plt.plot(ts_10[\"time\"], ts_10[\"conserved\"], label=r\"$\\Delta t = 1.0$ fs\")\n",
    "plt.plot(ts_05[\"time\"], ts_05[\"conserved\"], label=r\"$\\Delta t = 0.5$ fs\")\n",
    "plt.xlabel(\"time / ps\"); plt.ylabel(\"energy / a.u.\"); \n",
    "plt.ylim(ts_05[\"conserved\"][0]-0.01, ts_05[\"conserved\"][0]+0.01)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Note the sharp change in behavior of the conserved quantity. Plot also separately the potential and the kinetic energy. Is the dependence of the curves on $\\Delta t$ equally telling?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also spot the most dramatic problems by plotting the trajectories. Many MD problems manifest themselves in quite dramatic ways when looking at the motion of the atoms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_05 = pimdmooc.read_ipi_xyz(\"1-md_sampling/md-ts_0.5.pos_0.xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemiscope.show(frames = trajectory_05, properties = dict(\n",
    "   time = ts_05[\"time\"][::10],\n",
    "   potential = ts_05[\"potential\"][::10],\n",
    "   conserved = ts_05[\"conserved\"][::10]\n",
    "), settings = {'structure': [{ 'keepOrientation': True, 'playbackDelay': 10}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: molecules appear to be spread all over the place because they can move outside of the periodic boundaries (show the unit cell by selecting the appropriate option in the visualization menu)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to fold the atoms back into the supercell, and replot above\n",
    "for f in trajectory_05:\n",
    "    f.wrap(pbc=[1,1,1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the large timestep frames, the positions quickly go into NaN territory. you might be able to see the first stages of the explosion in the last valid frame in the trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_20 = pimdmooc.read_ipi_xyz(\"1-md_sampling/md-ts_2.0.pos_0.xyz\")\n",
    "n_ok = 0\n",
    "for f in trajectory_20:\n",
    "    if not np.isnan(f.positions.sum()):\n",
    "        n_ok+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemiscope.show(frames = trajectory_20[:n_ok], properties = dict(\n",
    "   time = ts_20[\"time\"][::10][:n_ok],\n",
    "   potential = ts_20[\"potential\"][::10][:n_ok],\n",
    "   conserved = ts_20[\"conserved\"][::10][:n_ok]\n",
    "), settings = {'structure': [{ 'keepOrientation': True, 'playbackDelay': 10}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "What would be an optimal time step for your simulation? What considerations would you make?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sampling-efficiency\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficiency of sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now consider more quantitatively the convergence of averages with Monte Carlo sampling. You need the definitions in [section 1](#thermo-and-sampling) so if you haven't executed that section yet, go back and run through the cells once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_traj(nstep, mcstep, q0=0):\n",
    "    q=q0\n",
    "    traj_q = np.zeros(nstep)\n",
    "    for i in range(nstep):    \n",
    "        q = metropolis_step(q, step=mcstep)\n",
    "        traj_q[i] = q\n",
    "    return traj_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the accuracy of sampling for $\\langle V \\rangle$, for which we know that the exact value has to be $1/2\\beta$.\n",
    "We repeat many times independent trajectories of the same length, and store the average potential along each trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: ntraj=100; nsteps=10000; mcstep=0.05\n",
    "ntraj = 100\n",
    "nsteps = 10000\n",
    "mcstep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmean = np.zeros(ntraj)\n",
    "for i in range(ntraj):\n",
    "    traj_q = mc_traj(nsteps, mcstep, q0=0)\n",
    "    vmean[i] =  pot_sho(traj_q, omega=omega0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error _of one trajectory_ can be computed as the standard deviation of the means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best estimate: <V>=%8.4f ± %8.4f\" % (vmean.mean(), vmean.std()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... this is much larger than if we used the textbook formula for the standard error in the mean of a trajectory with `nsteps` samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaults: nsteps=100000; mcstep=0.05\n",
    "nsteps = 100000\n",
    "mcstep = 0.05\n",
    "traj_v = pot_sho(mc_traj(nsteps, mcstep, q0=0), omega=omega0)\n",
    "print(\"Naive estimate:  <V>=%8.4f ± %8.4f\" % (traj_v.mean(), traj_v.std()/np.sqrt(nsteps)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the autocorrelation function and use it to get a better estimate of the error on a single trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelate(x, xbar=None):\n",
    "    \"\"\" Computes the autocorrelation function of a trajectory. \n",
    "    It can be given the exact average as a parameter\"\"\"\n",
    "    if xbar is None:\n",
    "        xbar = x.mean()\n",
    "    acf = np.correlate(x - xbar, x-xbar, mode='same')/((x-xbar)**2).sum()\n",
    "    return acf[len(x)//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the known analytical value of $\\langle V \\rangle$. _NB: it might take a minute or two to compute the autocorrelation function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vv = autocorrelate(traj_v, xbar=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_vv)\n",
    "plt.ylim(-0.1,1.1);\n",
    "plt.xlabel(r\"$\\Delta$ steps\"); plt.ylabel(r\"$c_{VV}$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the autocorrelation time and use it to correct the standard error in the mean to account for the correlation between samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_v = 2*c_vv[:nsteps//10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Autocorrelation time: %8.4f steps \" %(tau_v))\n",
    "print(\"Error from autocorrelation estimate:  <V>=%8.4f ± %8.4f\" % (traj_v.mean(), traj_v.std()/np.sqrt(nsteps/tau_v)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Repeat calculations for different values of `mcstep` between 0.01 and 1000. Keep note of the error and make a plot of $\\epsilon_V(\\Delta q)$.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "EV = [  ]  # enter the values you obtain here \n",
    "plt.loglog(MC, EV)\n",
    "plt.xlabel(r\"$\\Delta q$ / a.u.\"); plt.ylabel(r\"$\\epsilon_V$ / a.u.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: particularly when trajectories are not super-converged, using the mean from the trajectory to estimate the offset in computing $c_{VV}$ leads to a gross underestimation of the autocorrelation time and the error_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vv_trajmean = autocorrelate(traj_v, None)\n",
    "tau_v_trajmean = 2*c_vv_trajmean[:nsteps//10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(c_vv, label=r\"exact $\\langle V\\rangle$\")\n",
    "plt.plot(c_vv_trajmean, label=r\"traj. $\\langle V\\rangle$\")\n",
    "plt.ylim(-0.1,1.1); plt.legend()\n",
    "plt.xlabel(r\"$\\Delta$ steps\"); plt.ylabel(r\"$c_{VV}$\")\n",
    "print(\"Autocorrelation time (exact mean): %8.4f steps \" %(tau_v))\n",
    "print(\"Autocorrelation time (traj. mean): %8.4f steps \" %(tau_v_trajmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"langevin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langevin dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we run and analyze simulations that use Langevin dynamics to sample the canonical ensemble. If you have any problem running the i-PI trajectories you may want to check [section 2](#integrators) in which some of the practical steps are introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first go to the appropriate folder, create a copy of the template and edit it.  You will need to open a terminal and execute\n",
    "\n",
    "```\n",
    "$ cd pimd-mooc/1-md_sampling\n",
    "$ cp template_langevin.xml input.xml\n",
    "```\n",
    "\n",
    "You will notice that compared to the inputs in [section 2](#integrators) the simulation is run for a larger number of steps, and the `<dynamics>` block is set to `mode=\"nvt\"`, and it contains a `<thermostat>` block. Note also that velocities are initialized to an artificially low temperature, to emphasize the transient equilibration behavior.\n",
    "\n",
    "The key parameter here is the relaxation time of the thermostat, `tau`, that correspond to the reciprocal of the friction $\\tau=1/\\gamma$. Start by setting it to an intermediate value of 100 fs, and remember to also adjust the output prefix: use something like `<output prefix='md-langevin_100'>` to be compatible with the postprocessing in this notebook. Launch i-PI and the driver, and go grab a coffee, it will take a few minutes. \n",
    "\n",
    "Repeat the simulations with `tau` set to 1 fs and 10 ps. You can also run the simulations simultaneously if you have a multi-core system, but pay attention as you will have to also rename the socket `address` to avoid conflicts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the outputs and plot the trajectory of $V$ and $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_1 = pimdmooc.read_ipi_output('1-md_sampling/md-langevin_1.out')\n",
    "tau_100 = pimdmooc.read_ipi_output('1-md_sampling/md-langevin_100.out')\n",
    "tau_10000 = pimdmooc.read_ipi_output('1-md_sampling/md-langevin_10000.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tau_1['time'], tau_1['kinetic_md'], color=(0.5,0,0), label=r\"$K, \\tau=1$ fs\")\n",
    "plt.plot(tau_100['time'], tau_100['kinetic_md'], color=(1,0,0), label=r\"$K, \\tau=100$ fs\")\n",
    "plt.plot(tau_10000['time'], tau_10000['kinetic_md'], color=(1,0.5,0.5), label=r\"$K, \\tau=10$ ps\")\n",
    "plt.plot(tau_1['time'], tau_1['potential'], color=(0,0,0.5), label=r\"$V, \\tau=1$ fs\")\n",
    "plt.plot(tau_100['time'], tau_100['potential'], color=(0,0,1), label=r\"$V, \\tau=100$ fs\")\n",
    "plt.plot(tau_10000['time'], tau_10000['potential'], color=(0.5,0.5,1), label=r\"$V, \\tau=10$ ps\")\n",
    "plt.legend(ncol=2)\n",
    "plt.xlabel(\"time / ps\"); plt.ylabel(\"energy / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Compare the different curves. What qualitative considerations can you make on the efficiency and behavior of different thermostat parameters?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point to consider is that - even if the total energy $V+K$ (gray dotted line in the plot) is not conserved in a thermostatted trajectory - it is still possible to check the accuracy of the integrator by computing an artificial _conserved quantity_ $\\tilde{H}$, that is built by keeping track of the energy exchange between the system and the thermostat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tau_1['time'], tau_1['conserved'], color=(0,0,0.5), label=r\"$\\tilde{H}, \\tau=1$ fs\")\n",
    "plt.plot(tau_100['time'], tau_100['conserved'], color=(0,0,1), label=r\"$\\tilde{H}, \\tau=100$ fs\")\n",
    "plt.plot(tau_10000['time'], tau_10000['conserved'], color=(0.5,0.5,1), label=r\"$\\tilde{H}, \\tau=10$ ps\")\n",
    "plt.plot(tau_100['time'], tau_100['potential']+tau_100['kinetic_md'], color=(0.5,0.5,0.5), ls=\":\", label=r\"$H, \\tau=100$ fs\")\n",
    "plt.legend(ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to get more quantitative. We will compute autocorrelation functions and times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelate(x, xbar=None):\n",
    "    \"\"\" Computes the autocorrelation function of a trajectory. \n",
    "    It can be given the exact average as a parameter\"\"\"\n",
    "    if xbar is None:\n",
    "        xbar = x.mean()\n",
    "    acf = np.correlate(x - xbar, x-xbar, mode='same')/((x-xbar)**2).sum()\n",
    "    return acf[len(x)//2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that these are very short runs, to get a barely acceptable autocorrelation function we need to use reference values for the mean potential and kinetic energy. You could get these by running yourself a simulation with optimal thermostatting and at least a couple 100 ps length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_100['potential'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_v = -0.50735 # this is a reference value computed from a longer run\n",
    "mean_k = (96*3 - 3)*0.5*300*3.1668116e-06   # can you figure out why this is exactly the expected kinetic energy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_k_1 = autocorrelate(tau_1['kinetic_md'], mean_k)\n",
    "acf_k_100 = autocorrelate(tau_100['kinetic_md'], mean_k)\n",
    "acf_k_10000 = autocorrelate(tau_10000['kinetic_md'], mean_k)\n",
    "acf_v_1 = autocorrelate(tau_1['potential'], mean_v)\n",
    "acf_v_100 = autocorrelate(tau_100['potential'], mean_v)\n",
    "acf_v_10000 = autocorrelate(tau_10000['potential'], mean_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,3.5))\n",
    "acf_len = 10000\n",
    "ax[0].plot(tau_1['time'][:acf_len], acf_k_1[:acf_len], color=(0.5,0,0), label=r\"$K, \\tau=1$ fs\")\n",
    "ax[0].plot(tau_100['time'][:acf_len], acf_k_100[:acf_len], color=(1,0,0), label=r\"$K, \\tau=100$ fs\")\n",
    "ax[0].plot(tau_10000['time'][:acf_len], acf_k_10000[:acf_len], color=(1,0.5,0.5), label=r\"$K, \\tau=10$ ps\")\n",
    "ax[1].plot(tau_1['time'][:acf_len], acf_v_1[:acf_len], color=(0,0,0.5), label=r\"$V, \\tau=1$ fs\")\n",
    "ax[1].plot(tau_100['time'][:acf_len], acf_v_100[:acf_len], color=(0,0,1), label=r\"$V, \\tau=100$ fs\")\n",
    "ax[1].plot(tau_10000['time'][:acf_len], acf_v_10000[:acf_len], color=(0.5,0.5,1), label=r\"$V, \\tau=10$ ps\")\n",
    "for a in ax:\n",
    "    a.legend(ncol=1)\n",
    "    a.legend(ncol=1)\n",
    "    a.set_xlabel(\"time / ps\"); a.set_ylabel(\"energy / a.u.\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to update the reference for the GLE exercises, uncomment and execute these lines ...\n",
    "# np.savetxt(\"5-gle/ref_langevin_acf.dat\", np.vstack([tau_1['time'][:len(acf_k_1)], \n",
    "#    acf_v_1, acf_k_1, acf_v_100, acf_k_100, acf_v_10000, acf_k_10000]).T[:40000],\n",
    "#    header=\"time{ps}    acf_V(tau=1fs)   acf_K(tau=1fs)    acf_V(tau=100fs)   acf_K(tau=100fs)    acf_V(tau=10ps)   acf_K(tau=10ps)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Do the autocorrelation functions reflect the qualitative observations you had made just by looking at the equilibration trajectories?\n",
    "What does this tell us about the most effective choice of Langevin friction to compute efficiently structural averages?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something more:** _Try to recompute autcorrelation functions using the trajectory mean rather than the reference values. Would you get the same insights?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something more:** _These simulations are run starting from a non-equilibrated configuration, and initializing velocities to 1K. Try to re-run the same simulations but initializing velocities at 300K and using `h2o-32_equilibrated.xyz` as the initial configuration. How does this change the autocorrelation functions?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "397px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
