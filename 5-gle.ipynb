{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:32px; font-weight: bolder; text-align: center\"> Colored-noise methods </p>\n",
    "<p style=\"text-align: center\"><i> authored by: <a href=\"mailto:michele.ceriotti@gmail.com\"> Michele Ceriotti </a></i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a hands-on counterpart to the \"Colored-noise methods\" lecture for the MOOC \"Path Integrals in Atomistic Modeling\". If you haven't done so already, check the [getting started](0-getting_started.ipynb) notebook to make sure that the software infrastructure is up and running. \n",
    "\n",
    "The different sections in this notebook match the parts this lecture is divided into:\n",
    "\n",
    "1. [Generalized Langevin Equations](#gle)\n",
    "2. [Equilibrium GLE sampling](#equilibrium)\n",
    "3. [Non-Equilibrium GLE sanpling](#non-equilibrium)\n",
    "4. [Combining GLE and PIMD](#pi-gle)\n",
    "5. [Dynamical properties](#dynamics)\n",
    "\n",
    "<p style=\"color:blue; font-weight:bold\"> Questions in blue invite you to reflect on the results you are obtaining. If you are doing these notebooks as part of a course, there might be questions to answer relative to those parts. </p>\n",
    "\n",
    "_NB: you should run these sections in order, as the later ones re-use some of the data and the definitions from the earlier ones. If you cannot do the full notebook in a single session, re-running the full notebook should take less than a minute, as long as you leave the outputs of the external i-PI calculations in place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import ase, ase.io\n",
    "from ase.ga.utilities import get_rdf\n",
    "import chemiscope\n",
    "import pimdmooc\n",
    "pimdmooc.add_ipi_paths()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gle\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Langevin Equations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section provides a brief demonstration of the possibility of computing properties of a generalized Langevin equation written in the extended-phase-space form, as a function of the drift matrix $\\mathbf{A}_p$ and the diffusion matrix $\\mathbf{B}_p$ (the latter being usually fixed by a fluctuation-dissipation relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix $\\mathbf{M}_p$ coupling physical momentum $p$ and extended momenta $\\mathbf{s}$ can be written down as a combination of blocks, following the convention\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cc}\n",
    "      &    p   &   \\mathbf{s} \\\\ \\hline\n",
    "   p  & m_{pp} &  \\mathbf{m}_p^T \\\\\n",
    "\\mathbf{s} & \\bar{\\mathbf{m}}_p &  \\mathbf{M}\\\\\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this splits up a Mp matrix into the four blocks describing interactions between p and s\n",
    "def gle_split(Mp):\n",
    "    \"\"\" Splits a matrix in the various blocks \"\"\"\n",
    "    return Mp[:1,:1], Mp[:1, 1:], Mp[1:, :1], Mp[1:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest property that can be computed from the GLE matrices are the memory kernels of the associated non-Markovian formulation. The friction kernel reads\n",
    "\n",
    "$$\n",
    "K(t) = a_{pp} \\delta(t) - \\mathbf{a}_p^T e^{-t \\mathbf{A}} \\bar{\\mathbf{a}}_p\n",
    "$$\n",
    "\n",
    "and its Fourier transform \n",
    "\n",
    "$$\n",
    "K(\\omega) = 2 a_{pp} -2 \\mathbf{a}_p^T \\frac{\\mathbf{A}}{\\mathbf{A}^2+\\omega^2} \\bar{\\mathbf{a}}_p\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kt(Ap, t, with_delta=False):\n",
    "    app, ap, bap, A = gle_split(Ap)\n",
    "    return (app[0,0] if with_delta and t==0 else 0) - (ap@sp.linalg.expm(-A*t)@bap)[0,0]\n",
    "\n",
    "def Kw(Ap, w):\n",
    "    app, ap, bap, A = gle_split(Ap)\n",
    "    return (2*app  - 2*(ap@A)@np.linalg.solve(A@A+np.eye(len(A))*w**2,bap))[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different analytical forms of memory kernel can be obtained with appropriate parameterizations of the drift matrix. The ones given below yield $K(t)$ that are exponential, $K(t)=\\gamma e^{-t/\\tau}$ or different types of Dirac-$\\delta$-like functions, that give a peaked memory kernel in the frequency domain (the corresponding functional form is rather cumbersome, you can find a thorough discussion [here](https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/152344/eth-2145-02.pdf)) - the functional form has been slightly modified to give more intuitive link between the parameters and the shape of $K(\\omega)$. In all these cases, the parameter `app`, corresponding to $a_{pp}$, introduces an explicit Markovian term in the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ap_exp(gamma, tau, app=0):\n",
    "    \"\"\" Drift matrix for an exponential memory kernel.\n",
    "    gamma: intensity of the friction\n",
    "    tau: time scale of the exponential decay\n",
    "    app: Markovian term\n",
    "    \"\"\"\n",
    "    return np.asarray( [ [app,-np.sqrt(gamma/tau) ], [np.sqrt(gamma/tau), 1/tau ]])\n",
    "def Ap_delta(gamma, omega0, domega, app=0):\n",
    "    \"\"\" Drift matrix for a delta-like memory kernel.  \n",
    "    gamma: intensity of the friction\n",
    "    omega0: frequency-domain center of the K(w) peak\n",
    "    domega: width of the peak\n",
    "    app: Markovian term\n",
    "    \"\"\"\n",
    "    return np.asarray( [ [app, np.sqrt(gamma*domega/2), np.sqrt(gamma*domega/2) ], \n",
    "                         [-np.sqrt(gamma*domega/2),  domega, omega0 ],\n",
    "                         [-np.sqrt(gamma*domega/2), -omega0, domega ]\n",
    "                       ])\n",
    "def Ap_delta_alt(gamma, omega0, domega, app=0):\n",
    "    \"\"\" Drift matrix for a delta-like memory kernel. Alternative form with K(0)=0. \n",
    "    gamma: intensity of the friction\n",
    "    omega0: frequency-domain center of the K(w) peak\n",
    "    domega: width of the peak\n",
    "    app: Markovian term\n",
    "    \"\"\"\n",
    "    return np.asarray( [ [app,np.sqrt(gamma*domega/2), 0 ], \n",
    "                         [-np.sqrt(gamma*domega/2),  domega, omega0 ],\n",
    "                         [0, -omega0, 0 ]\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can plot $K(\\omega)$ for the three functional forms above. Play around with the parameters to verify their effect on the shape of the memory kernel spectrum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgrid = np.geomspace(1e-3,1e3,200)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "# defaults: Ap_delta_alt(1, 1, 1, 1e-8)\n",
    "ax.loglog(wgrid, [Kw(Ap_delta_alt(1, 1, 0.1, 1e-8), w) for w in wgrid], 'r-' )  \n",
    "# defaults: Ap_delta(1, 0.1, 0.01, 1e-8)\n",
    "ax.loglog(wgrid, [Kw(Ap_delta(1, 0.1, 0.01, 1e-8), w) for w in wgrid], 'b-' ) \n",
    "# defaults: Ap_exp(1, 1, 0)\n",
    "ax.loglog(wgrid, [Kw(Ap_exp(1, 1, 0), w) for w in wgrid], 'k-' )\n",
    "ax.set_xlabel(r\"$\\omega$ / a.u.\"); ax.set_ylabel(r\"$K(\\omega)$ / a.u.\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important idea that makes it easy to reuse GLE parameters for different systems is that it is possible to \"translate\" the shape of $K(\\omega)$ by scaling it by a factor $\\alpha$. This is essentially a change of units, so scaling the kernel moves the curve right and up in the $(\\omega, K)$ plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgrid = np.geomspace(1e-3,1e3,200)\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.loglog(wgrid, [Kw(Ap_delta_alt(1,1,1,1e-4), w) for w in wgrid], 'r-' )\n",
    "ax.loglog(wgrid, [Kw(0.1*Ap_delta_alt(1,1,1,1e-4), w) for w in wgrid], 'r:' )\n",
    "ax.loglog(wgrid, [Kw(10*Ap_delta_alt(1,1,1,1e-4), w) for w in wgrid], 'r--' )\n",
    "ax.set_xlabel(r\"$\\omega$ / a.u.\"); ax.set_ylabel(r\"$K(\\omega)$ / a.u.\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "In the case of the analytical memory functions above, you can actually also mimic the effect of scaling by changing the value of the parameters. What parameters should you use for Ap_delta below, so that the blue curve becomes identical to the red curve?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.loglog(wgrid, [Kw(0.1*Ap_delta(1,1,0.1,1e-4), w) for w in wgrid], 'r--' )\n",
    "\n",
    "# modify the parameters below ↓ ↓ ↓ ↓, corresponding to gamma, omega0, domega, app\n",
    "ax.loglog(wgrid, [Kw(Ap_delta(1,1,1,0), w) for w in wgrid], 'b:' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLE integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now see how a GLE can be integrated in its Markovian, extended-phase-space form. The idea is very similar to the integrator for Langevin dynamics: a free-particle propagator that propagates $(p, \\mathbf{s})$ for a finite time step $dt$ without an external potential is combined with a velocity-Verlet integrator for the Hamiltonian part of the equations of motion. The GLE integrator can be formulated as \n",
    "\n",
    "$$\n",
    "(p, \\mathbf{s})^T \\leftarrow \\mathbf{T}_p (p, \\mathbf{s})^T + \\mathbf{S}_p \\boldsymbol{\\xi}^T\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\xi}$ is a vector of uncorrelated random numbers, $\\mathbf{T}_p = e^{-\\mathbf{A}_p dt}$, and $\\mathbf{S}_p\\mathbf{S}_p^T = \\mathbf{C}_p - \\mathbf{T}_p \\mathbf{C}_p \\mathbf{T}_p^T$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example classes for VV and GLE integration. Should be rather self-explanatory. \n",
    "# We consider a particle with unit mass\n",
    "class VVIntegrator(object):\n",
    "    \"\"\" Velocity-Verlet integrator \"\"\"\n",
    "    def __init__(self, force, dt, q):\n",
    "        \"\"\" force is a function that takes a vector of positions q and returns -dV/dq \"\"\"\n",
    "        self.force = force\n",
    "        self.dt = dt\n",
    "        self.f = force(q)\n",
    "    \n",
    "    def step(self, q, p):        \n",
    "        p[:] += self.f * self.dt *0.5\n",
    "        q[:] += p * self.dt\n",
    "        self.f = self.force(q)\n",
    "        p[:] += self.f * self.dt*0.5            \n",
    "        \n",
    "class GLEIntegrator(object):\n",
    "    \"\"\" Finite time-step GLE integrator for a free particle \"\"\"\n",
    "    def __init__(self, Ap, Cp, dt):\n",
    "        self.ns = len(Ap)-1\n",
    "        self.Ap = Ap\n",
    "        self.Cp = Cp\n",
    "        self.dt = dt\n",
    "        self.T = sp.linalg.expm(-Ap*self.dt*0.5)\n",
    "        self.S = sp.linalg.cholesky(self.Cp - self.T @ self.Cp @self.T.T).T\n",
    "    \n",
    "    def step(self, p, s):        \n",
    "        ps = np.vstack([p,s])\n",
    "        # stores the \"GLE force\" contribution for analysis\n",
    "        self._rf = self.T @ ps - ps + self.S @ np.random.normal(size=(self.ns+1, len(p)))\n",
    "        ps += self._rf        \n",
    "        p[:] = ps[0]\n",
    "        s[:] = ps[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then run a trajectory for a free particle, using an exponential memory kernel. We run a 2D trajectory, but the two directions are equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the trajectory\n",
    "q = np.asarray([0.,0.])\n",
    "p = np.asarray([0.,0.])\n",
    "s = np.asarray([[0.,0.]])\n",
    "dt = 0.1\n",
    "Ap = Ap_exp(0.2, 10, 0.01)  # default value: Ap_exp(0.2, 10, 0.01)\n",
    "GLE = GLEIntegrator(Ap, np.eye(s.shape[0]+1), dt)\n",
    "VV = VVIntegrator(lambda x:0.*x, dt, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstep = 40000 # default value: 40000\n",
    "traj_q = np.zeros((nstep, len(q)))\n",
    "traj_p = np.zeros((nstep, len(p)))\n",
    "traj_f = np.zeros((nstep, len(p)))\n",
    "for istep in range(nstep):\n",
    "    traj_q[istep] = q; traj_p[istep] = p\n",
    "    GLE.step(p,s)\n",
    "    traj_f[istep] = GLE._rf[0]/(0.5*dt) # this is \\dot{p} + V'(q), see the exercise in the lecture notes\n",
    "    VV.step(q,p)\n",
    "    GLE.step(p,s)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,4), constrained_layout=True)\n",
    "ax.plot(traj_q[:,0], traj_q[:,1], 'r-')\n",
    "ax.set_xlabel(\"$q_1$\"); ax.set_ylabel(\"$q_2$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trajectory of the particle is quite different from what you would get with a white-noise Langevin run. Experiment with different parameters and types of the `Ap` matrix. \n",
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Run a white-noise simulation with a_pp = 0.2 (you can achieve this by manually constructing an Ap matrix, or by setting gamma=0 in the exponential kernel). Observe the difference in the trajectory behavior: can you recognize this out of several trajectories generated with colored noise?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"equilibrium\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrium GLE sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section requires use of i-PI, so make sure you have it installed and have familiarized yourself with how to run it in the [getting started](0-getting_started.ipynb) section. \n",
    "\n",
    "We will set up and run a molecular dynamics simulation of liquid water using a \"smart-sampling\" GLE thermostat, using the parameter generator from the [GLE4MD website](https://gle4md.org). Given that we will compare the sampling efficiency to that obtained from white-noise Langevin simulations, you may want to run the exercises from section 4 of the [sampling and MD notebook](1-md_sampling.ipynb). \n",
    "\n",
    "For reference, these are the values of the correlation times for $V$ and $K$ obtained from a long simulation with different white noise thermostat relaxation time $\\tau=1/\\gamma$\n",
    "\n",
    "\n",
    "|  $\\tau$ / fs   |    $\\tau_V$ / ps  |   $\\tau_K$ / ps   |\n",
    "|----------------|-------------------|-------------------|\n",
    "|     1          |        10         |      0.0009       |\n",
    "|    100         |        0.8        |      0.04         |\n",
    "|   10000        |        4.6        |      1.5          |\n",
    "\n",
    "We also load some reference data that was generated with those trajectories, that contains the correlation functions of potential and kinetic energy at different Langevin $\\tau$ (format: `[time{ps}, acf_V(tau=1fs),   acf_K(tau=1fs), acf_V(tau=100fs), acf_K(tau=100fs), acf_V(tau=10ps), acf_K(tau=10ps)]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data = np.loadtxt('5-gle/ref_langevin_acf.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can prepare the GLE trajectory. Make a copy of the template file\n",
    "\n",
    "```\n",
    "$ cd pimd-mooc/5-gle\n",
    "$ cp template_gle.xml input.xml\n",
    "```\n",
    "\n",
    "and modify it to use a GLE thermostat. We will use a \"smart-sampling\" GLE, so set the prefix to `md-gle_smart`, to match the post-processing below.\n",
    "\n",
    "Then, the important part: setting the GLE parameters. We will use the on-line generator on the [GLE4MD](https://gle4md.org) website. The website does not fit parameters from scratch, but uses a library of pre-optimized parameters, and uses scaling rules to adjust them for the range of frequencies of interest. \n",
    "\n",
    "![the input generation interface on gle4md.org](figures/gle4md-screenshot.png)\n",
    "\n",
    "\"Smart\" GLE thermostats are designed to provide optimal sampling efficiency for a characteristic time scale. We set it to 5 ps, given that the example is limited to 20ps and so 5-10ps is the longest time scale we can hope to target. By choosing a parameters preset that targets 3 orders of magnitude in frequency, we get \"as efficient as possible\" sampling up to about 6000 cm<sup>-1</sup>, well above the highest vibrational frequencies in water that are around 3600 cm<sup>-1</sup>. We set the formatting to i-PI output, that generates an XML block that should be copied and pasted within the `<dynamics>` block in the input file. \n",
    "You can get parameters that are suitable for water following [this link](https://gle4md.org/index.html?page=matrix&kind=smart&tslow=5&utslow=ps&smrange=6-3&outmode=ipi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having set up the input file, you can run it as usual, launching i-PI first, and then the driver code that computes q-TIP4P/f energies and forces. \n",
    "\n",
    "```\n",
    "$ i-pi input.xml &> log &\n",
    "$ i-pi-driver -u -h driver -m qtip4pf \n",
    "```\n",
    "\n",
    "Wait until the run has completed, then load the output trajectory and continue the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_gle = pimdmooc.read_ipi_output('5-gle/md-gle_smart.out')\n",
    "pos_gle = pimdmooc.read_ipi_xyz('5-gle/md-gle_smart.pos_0.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the radial distribution functions, to get an idea of the structure of the liquid. These will also be used further down to compare with quantum simulations.\n",
    "_NB: ASE normalizes partial RDF in such a way they do not tend to 1 for a homogeneous system. We correct manually the normalization_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbins = get_rdf(pos_gle[0], rmax=4.5, nbins=200, elements=[8, 8])[1] \n",
    "rdf_cls_oo = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 8])[0] for f in pos_gle[::10]]).mean(axis=0)/(1/3)\n",
    "rdf_cls_oh = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 1])[0] for f in pos_gle[::10]]).mean(axis=0)/(2/3)\n",
    "rdf_cls_hh = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[1, 1])[0] for f in pos_gle[::10]]).mean(axis=0)/(2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(rbins, rdf_cls_oo, 'r-' )\n",
    "ax.plot(rbins, rdf_cls_oh, c='gray' )\n",
    "ax.plot(rbins, rdf_cls_hh, 'c-' )\n",
    "ax.set_xlabel(r\"$r / \\AA$\"); ax.set_ylabel(r\"RDF\"); \n",
    "ax.set_ylim(-0.1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the autocorrelation function of potential and kinetic energy for the trajectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf_v_gle = pimdmooc.autocorrelate(traj_gle[\"potential\"], normalize=True)\n",
    "acf_k_gle = pimdmooc.autocorrelate(traj_gle[\"kinetic_md\"], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integral-by-sum (we truncate at ~5ps because of the high level of noise)\n",
    "tau_v = (acf_v_gle[:5000].sum() - 0.5*acf_v_gle[0])*traj_gle[\"time\"][1]\n",
    "tau_k = (acf_k_gle[:5000].sum() - 0.5*acf_k_gle[0])*traj_gle[\"time\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Autocorrelation time: tau_V = % 10.5f ps,  tau_K = % 10.5f ps\" % (tau_v, tau_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,3.5))\n",
    "acf_len = 10000\n",
    "ax[0].plot(ref_data[:acf_len,0], ref_data[:acf_len,2], color=(0.5,0,0,0.5), label=r\"$K, \\tau=1$ fs\")\n",
    "ax[0].plot(ref_data[:acf_len,0], ref_data[:acf_len,4], color=(1,0,0,0.5), label=r\"$K, \\tau=100$ fs\")\n",
    "ax[0].plot(ref_data[:acf_len,0], ref_data[:acf_len,6], color=(1,0.5,0.5,0.5), label=r\"$K, \\tau=10$ ps\")\n",
    "ax[0].plot(ref_data[:acf_len,0], acf_k_gle[:acf_len], color='k', label=r\"$K, $ GLE\")\n",
    "ax[1].plot(ref_data[:acf_len,0], ref_data[:acf_len,1], color=(0,0,0.5,0.5), label=r\"$V, \\tau=1$ fs\")\n",
    "ax[1].plot(ref_data[:acf_len,0], ref_data[:acf_len,3], color=(0,0,1,0.5), label=r\"$V, \\tau=100$ fs\")\n",
    "ax[1].plot(ref_data[:acf_len,0], ref_data[:acf_len,5], color=(0.5,0.5,1,0.5), label=r\"$V, \\tau=10$ ps\")\n",
    "ax[1].plot(ref_data[:acf_len,0], acf_v_gle[:acf_len], color='k', label=r\"$V, $ GLE\")\n",
    "for a in ax:\n",
    "    a.legend(ncol=1)\n",
    "    a.legend(ncol=1)\n",
    "    a.set_xlabel(\"time / ps\"); a.set_ylabel(\"energy / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Observe the autocorrelation functions, and compare them with those obtained by white-noise thermostats. \n",
    "</p>\n",
    "<em>NB: the reference trajectories are obtained from much longer simulations, so they have smaller error in the asymptotic regime. Those from the GLE run will be noisier so you have to use a bit of \"mental filtering\". You can set up the GLE run to be longer, if you can afford the wait!</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Imagine what would happen if you set the masses of all the atoms to be 100 times larger. What would you change in the setup of the simulation, what would change in the results and what will not?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"non-equilibrium\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-equilibrium GLE sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see what happens when using a GLE simulation that does not fulfill the classical fluctuation-dissipation theorem, $k_B T(\\mathbf{A}_p+\\mathbf{A}_p^T)\\ne \\mathbf{B}_p \\mathbf{B}_p^T$. \n",
    "In fact, the GLE still reaches (in the free-particle limit) a stationary state for which the covariance matrix $\\mathbf{C}_p$ is not diagonal, and is consistent with $\\mathbf{A}_p \\mathbf{C}_p+\\mathbf{C}_p\\mathbf{A}_p^T = \\mathbf{B}_p \\mathbf{B}_p^T$: in practice, one usually considers $\\mathbf{C}_p$ as the GLE parameter, given also that $\\mathbf{B}_p$ is not needed to compute the finite-time propagator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrate the use of a _quantum thermostat_, in which $\\mathbf{A}_p$ and $\\mathbf{C}_p$ are optimized to yield a distribution of $\\langle q\\rangle^2$ and  $\\langle p\\rangle^2$ consistent with the quantum expectation values for a harmonic oscillator of frequency $\\omega_0$. \n",
    "\n",
    "Similar to the equilibrium case, several pre-optimized GLE parameters (that also balance sampling efficiency and zero-point energy leakage) can be obtained from the [GLE4MD website](https://gle4md.org). Scaling rules make it possible to adjust the target temperature, and the most important parameter is the maximum frequency for which the quantum fluctuations are guaranteed to be correct in the harmonic limit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum thermostat for a harmonic oscillator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration, we run a simulation for a 3D harmonic oscillator. Everything is expressed in atomic units, the target temperature is $T=1$ and the frequencies are $\\omega_0 = 0.25, 1, 4$: the lowest frequency is in the classical regime, the intermediate one is at the turning point between classical and quantum, and the highest frequency is strongly quantized.  Given that for the highest frequency $\\hbar\\omega\\beta=4$, the presets which fits fluctuations up to $\\hbar\\omega\\beta=20$ is more than sufficient. \n",
    "The GLE parameters below are obtained from the [online GLE input generator](https://gle4md.org/index.html?page=matrix&kind=quantum&parset=20_6&temp=1&utemp=aue&outmode=python&aunits=aut&cunits=aue)\n",
    "\n",
    "_NB: this uses the subroutines defined in [section 1](#gle)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the trajectory\n",
    "q = np.asarray([0.,0.,0.])\n",
    "p = np.asarray([0.,0.,0.])\n",
    "s = np.zeros(shape=(6,3))\n",
    "dt = 0.1  # default: 0.1\n",
    "# strong bhw=20 quantum thermostat matrices for beta=1 a.u., from the GLE4MD website\n",
    "Ap = np.asarray([\n",
    "[   9.940227881069e-3,    1.191832744031e+0,    7.841346537680e-1,    1.127422061083e+0,    1.287760047739e+0,    6.597371849521e-1,    3.854520538662e-1, ],\n",
    "[  -1.219402549722e+0,    5.187757030411e-1,    1.679849599124e+0,   -2.171362088679e-1,   -5.679884059178e-2,    1.678648983902e-1,   -1.694069965777e+0, ],\n",
    "[  -7.396592199758e-1,   -1.679849599124e+0,    5.313365730649e-1,    2.916457167952e-1,    7.922023001118e-1,    2.804659293960e-1,   -8.312829730079e-1, ],\n",
    "[  -1.129202488515e+0,    2.171362088679e-1,   -2.916457167952e-1,    6.075528350225e-1,    2.238529963876e-2,    7.625335027833e-1,    3.896382327408e-1, ],\n",
    "[  -1.251885757500e+0,    5.679884059178e-2,   -7.922023001118e-1,   -2.238529963876e-2,    6.636392814216e-1,   -8.806083934866e-1,    2.480987428195e+0, ],\n",
    "[  -3.314567459043e-1,   -1.678648983902e-1,   -2.804659293960e-1,   -7.625335027833e-1,    8.806083934866e-1,    6.023159253293e+0,   -8.283882517564e+0, ],\n",
    "[  -7.647113842221e-1,    1.694069965777e+0,    8.312829730079e-1,   -3.896382327408e-1,   -2.480987428195e+0,    8.283882517564e+0,    9.760847161873e+0, ],\n",
    "])\n",
    "Cp = np.asarray([\n",
    "[   9.999953047000e-1,    1.979197779000e-2,    7.147922505000e-1,    1.961018636000e-1,   -3.732679220000e-1,   -2.264460588000e-1,    4.599299108000e-2, ],\n",
    "[   1.979197779000e-2,    1.260617101000e+0,   -1.931506174000e-1,   -7.262575605000e-1,   -5.497702197000e-1,   -2.185704484000e-1,    1.277943581000e-1, ],\n",
    "[   7.147922505000e-1,   -1.931506174000e-1,    2.441919995000e+0,    7.295025710000e-1,   -1.234862177000e+0,   -1.128397955000e-1,   -1.609235586000e-2, ],\n",
    "[   1.961018636000e-1,   -7.262575605000e-1,    7.295025710000e-1,    2.320143840000e+0,   -1.210057031000e+0,    5.676469950000e-1,   -2.024421968000e-1, ],\n",
    "[  -3.732679220000e-1,   -5.497702197000e-1,   -1.234862177000e+0,   -1.210057031000e+0,    4.792907650000e+0,    3.749158013000e-1,    1.177918093000e-2, ],\n",
    "[  -2.264460588000e-1,   -2.185704484000e-1,   -1.128397955000e-1,    5.676469950000e-1,    3.749158013000e-1,    4.964464101000e+0,   -5.358672711000e-1, ],\n",
    "[   4.599299108000e-2,    1.277943581000e-1,   -1.609235586000e-2,   -2.024421968000e-1,    1.177918093000e-2,   -5.358672711000e-1,    1.481694550000e+0, ],\n",
    "]\n",
    ")\n",
    "\n",
    "GLE = GLEIntegrator(Ap, Cp, dt)\n",
    "omega = np.asarray([0.25,1,4])   # default: [0.25,1,4]\n",
    "VV = VVIntegrator(lambda x: -x*omega**2, dt, q) # harmonic force as a lambda function ^_^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstep = 200000 # default value: 200000\n",
    "traj_q = np.zeros((nstep, len(q)))\n",
    "traj_p = np.zeros((nstep, len(p)))\n",
    "for istep in range(nstep):\n",
    "    traj_q[istep] = q; traj_p[istep] = p\n",
    "    GLE.step(p,s)\n",
    "    VV.step(q,p)\n",
    "    GLE.step(p,s)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... do you recognize the expressions for the distribution of $q$ for a harmonic oscillator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cho_pq(w, beta, q):\n",
    "    \"\"\" Distribution of q for a classical harmonic oscillator. \"\"\"\n",
    "    q2 = beta/w**2\n",
    "    return np.exp(-0.5*q**2/q2)/np.sqrt(2*np.pi*q2)\n",
    "def qho_pq(w, beta, q):\n",
    "    \"\"\" Distribution of q for a quantum harmonic oscillator. \"\"\"\n",
    "    q2 = 0.5*beta/w /np.tanh(beta*w/2)\n",
    "    return np.exp(-0.5*q**2/q2)/np.sqrt(2*np.pi*q2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of positions sampled by the quantum thermostat follows closely the _quantum_ distribution, as it can be seen by plotting the histogram of positions (note that statistical convergence might be a problem, you can try increase the duration of the simulation to obtain more precise convergence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrid = np.linspace(-15,15,1000)\n",
    "fig, ax = plt.subplots(1,3,figsize=(11,3), constrained_layout=True)\n",
    "for i in range(3):\n",
    "    ax[i].hist(traj_q[:,i], bins=100, density=True, label=\"quantum thermostat\", color=\"gray\");\n",
    "    ax[i].plot(qgrid, qho_pq(omega[i], 1, qgrid), 'r-', label=\"quantum HO\")\n",
    "    ax[i].plot(qgrid, cho_pq(omega[i], 1, qgrid), 'b--', label=\"classical HO\")\n",
    "    ax[i].set_xlim(-5/omega[i], 5/omega[i])\n",
    "    ax[i].set_title(r\"$\\omega=$\"+str(omega[i]))\n",
    "    ax[i].set_xlabel(r\"$q$ / a.u.\")\n",
    "ax[2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to run with higher frequencies. Is the simulation still accurate when $\\omega>20$? \n",
    "_NB: as you increase the oscillator frequency you may have to reduce the time step._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum thermostat for liquid water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modify the `template_gle.xml` input file (after copying it to a different name) to perform a quantum thermostat simulation for water at 300K. It is recommended that you use `prefix='md-gle_qt'`, to be consistent with the post-processing code below.\n",
    "Try to choose the parameters on [GLE4MD website](https://gle4md.org/index.html?page=matrix). Strongly coupled matrices that guarantee quantum behavior up to a cutoff frequency around 4000 cm<sup>-1</sup> should be suitable. \n",
    "If you are uncertain or want to check your selection, compare it with [the recommended parameters](https://gle4md.org/index.html?page=matrix&kind=quantum&parset=20_6&temp=300&utemp=k&outmode=ipi).\n",
    "\n",
    "After having run the simulations, we can look at the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_qt = pimdmooc.read_ipi_output('5-gle/md-gle_qt.out')\n",
    "pos_qt = pimdmooc.read_ipi_xyz('5-gle/md-gle_qt.pos_0.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print out separately the kinetic temperature of oxygen and hydrogen atoms. This is a striking indication of the non-equilibrium nature of the thermostat, if seen in a classical sense: the kinetic energy of H atoms differs dramatically from that of the O atoms, and the overall kinetic energy is much higher than that one would expect from classical equipartition at $T=300$ K.\n",
    "\n",
    "_NB: let us reiterate that the temperature computed from the kinetic energy is *not* a valid proxy of the thermodynamic temperature in a quantum simulation, because the relationship between mean kinetic energy per degree of freedom and $T$ only holds in the classical case._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(traj_qt[\"time\"], traj_qt[\"temperature(O)\"], 'r', ls=\"-\" , label=\"O\")\n",
    "ax.plot(traj_qt[\"time\"], traj_qt[\"temperature(H)\"], 'c', ls=\"-\", label=\"H\" )\n",
    "ax.plot(traj_qt[\"time\"], traj_qt[\"temperature\"], 'k', ls=\"-\", label=\"all\" )\n",
    "ax.set_xlabel(r\"$t$ / ps\"); ax.set_ylabel(r\"T / K\"); \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then look at the radial distribution functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbins = get_rdf(pos_qt[0], rmax=4.5, nbins=200, elements=[8, 8])[1] \n",
    "rdf_qt_oo = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 8])[0] for f in pos_qt[1000::10]]).mean(axis=0)/(1/3)\n",
    "rdf_qt_oh = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 1])[0] for f in pos_qt[1000::10]]).mean(axis=0)/(2/3)\n",
    "rdf_qt_hh = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[1, 1])[0] for f in pos_qt[1000::10]]).mean(axis=0)/(2/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sees that the long-range parts of the RDF, and most of the O-O pair distribution, are not affected by the quantum thermostat. This is very similar to the result of PIMD simulations with this potential. On the other hand, intra-molecular degrees of freedom, identified by the first peak in the O-H and H-H RDF, are much broader, reflecting the larger quantum fluctuations driven by the GLE, that simulates the effect of zero-point energy motion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that this reuses the classical RDF from section 2\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(rbins, rdf_cls_oo, 'r', ls=\":\" )\n",
    "ax.plot(rbins, rdf_cls_oh, c='gray', ls=\":\" )\n",
    "ax.plot(rbins, rdf_cls_hh, 'c', ls=\":\" )\n",
    "ax.plot(rbins, rdf_qt_oo, 'r', ls=\"-\" )\n",
    "ax.plot(rbins, rdf_qt_oh, c='gray', ls=\"-\" )\n",
    "ax.plot(rbins, rdf_qt_hh, 'c', ls=\"-\" )\n",
    "ax.set_xlabel(r\"$r / \\AA$\"); ax.set_ylabel(r\"RDF\"); \n",
    "ax.set_ylim(-0.1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Plot the potential and kinetic energy (or compute directly the mean), for both this trajectory and the classical GLE simulation in section 2. How much additional energy per water molecule is present in the system due to quantum fluctuations?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: remember that i-PI returns energies in atomic units. one atomic unit of energy equals approximately 27.2 eV_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something more:** _Re-run these simulations using the \"weak coupling\" GLE. You should observe colder H, hotter O, and loss of structure in the long-range part of the RDF, that are all indications of zero-point energy leakage from high-frequency to low-frequency vibrations_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pi-gle\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining GLE and PIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quantum thermostat, demonstrated in the [previous section](#non-equilibrium), provides an inexpensive way to simulate quantum fluctuations in both harmonic and quasi-harmonic systems. In the presence of large anharmonicities, however, or for extremely low temperatures, this is only an approximation, and one that cannot be systematically tested or improved upon. One possibility is to use a GLE *on top of a PIMD simulation*, so as to be able to converge progressively the thermostat to equilibrium sampling in the ring-polymer phase space, as the number of replicas $P$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: Path integral simulations, even with GLE acceleration, are rather time consuming. The default duration (10ps) is on the short side, so expect higher statistical errors than in other exercises. Even with short simulations, these will take more than one hour so we suggest you set up all simulations in parallel (e.g. in different terminal tabs), using different UNIX socket names, and let them run while you take a break._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we run with different # of beads, so we'll store the trajectory data in arrays\n",
    "traj_pg = {}\n",
    "pos_pg = {}\n",
    "p_list = [2,4,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by setting up simulations using `template_piglet.xml` as a template. As usual, copy to a different file name before editing, to leave a clean template. Beside setting prefix and socket name to indicate the number of beads in the simulation, you will have to set two key parameters: the actual number of beads in the simulation, the `nbeads='xxx'` attribute in the `<initialize>` tag, and the actual GLE parameters. \n",
    "\n",
    "You can fetch those from [GLE4MD](https://gle4md.org) rather easily, although the settings panel is somewhat richer than for simpler GLE schemes:\n",
    "\n",
    "![the input generation interface for PIGLET parameters](figures/gle4md-piglet.png)\n",
    "\n",
    "Most importantly, you need to set the number of beads to match that in the simulation. Since PIGLET adds in normal-modes coordinates, the input you'll have to copy is rather cumbersome, with a separate set of GLE parameters for each normal mode of the ring polymer. Then, you need to set a separate thermostat for the centroid. The \"optimal sampling\" scheme is recommended, not only for the sampling efficiency but also because it effectively contrasts zero-point energy leakage - which is still an issue, although less so than in the case of the quantum thermostat. \n",
    "The other parameters should be self-explanatory. You can check your parameters against [this example](https://gle4md.org/index.html?page=matrix&kind=piglet&centroid=kh_8-4&cw0=4000&ucw0=cm1&nbeads=2&temp=300&utemp=k&parset=20_8_t&outmode=ipi) for the $P=2$ case. \n",
    "\n",
    "Set up and run simulations for $P=2, 4, 6$, then move on to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_list:\n",
    "    traj_pg[p] = pimdmooc.read_ipi_output(f'5-gle/md-piglet_{p}.out')\n",
    "    pos_pg[p] = pimdmooc.read_ipi_xyz(f'5-gle/md-piglet_{p}.pos_0.xyz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the kinetic temperature of the simulation. **This number is completely meaningless** in physical terms, because of the complicated thermostatting scheme: the kinetic energy of the system is computed by the centroid-virial estimator, which we will use later. However it is useful to verify the non-equilibrium nature of the thermostat: for $P\\rightarrow\\infty$, where the path integral formalism alone should suffice to achieve quantum sampling, the estimator should converge to the target temperature of the simulation, T=300K. Plot the kinetic temperature of O and H atoms for the different numbers of beads, and see how they converge. Note also the very fast initial relaxation: this is because the run is initiated from a single configuration, and the beads rapidly spread out to the extent of ring polymer fluctuations. Full equilibration - particularly for structural properties - may take longer. \n",
    "_NB: this is a rather naive argument, and the convergence of PIGLET temperatures to 300K is rather slow due to the actual definitions of target temperatures. You should however notice the reduction in temperature difference between H and O, which is indicative of the reduced impact of zero-point energy leakage._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 6\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.set_title(f\"PIGLET simulations, P={p}\")\n",
    "ax.plot(traj_pg[p][\"time\"], traj_pg[p][\"temperature(O)\"], 'r', ls=\"-\" , label=\"O\")\n",
    "ax.plot(traj_pg[p][\"time\"], traj_pg[p][\"temperature(H)\"], 'c', ls=\"-\", label=\"H\" )\n",
    "ax.plot(traj_pg[p][\"time\"], traj_pg[p][\"temperature\"], 'k', ls=\"-\", label=\"all\" )\n",
    "ax.set_xlabel(r\"$t$ / ps\"); ax.set_ylabel(r\"T / K\"); \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also plot the actual potential and kinetic energy for the different runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 6\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.set_title(f\"PIGLET simulations, P={p}\")\n",
    "ax.plot(traj_pg[p][\"time\"], traj_pg[p][\"potential\"], 'r', ls=\"-\" , label=\"V\")\n",
    "ax.plot(traj_pg[p][\"time\"], traj_pg[p][\"kinetic_cv\"], 'b', ls=\"-\", label=\"K\" )\n",
    "ax.set_xlabel(r\"$t$ / ps\"); ax.set_ylabel(r\"energy / a.u.\"); \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the means demonstrate the fast quantitative convergence of the scheme to the quantum expectation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_v = []\n",
    "mean_k = []\n",
    "mean_v_cls = -0.50735 # this is a reference value computed from a long classical run\n",
    "mean_k_cls = (96*3 - 3)*0.5*300*3.1668116e-06 # exact classical kinetic energy\n",
    "mean_v_qm = -2.065e-01 # reference from a long PIMD run with 16 beads and Suzuki-Chin\n",
    "mean_k_qm = 4.324e-01\n",
    "for p in p_list:\n",
    "    mean_v.append(traj_pg[p][\"potential\"][1000:].mean())\n",
    "    mean_k.append(traj_pg[p][\"kinetic_cv\"][1000:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(p_list, mean_v, 'r', ls=\"-\" , marker = 'o', label=\"V\")\n",
    "ax.plot(p_list, mean_k, 'b', ls=\"-\", marker=\"*\", label=\"K\" )\n",
    "ax.hlines(mean_v_cls, 2, 6, color='r', ls=\":\", label=\"V (cls)\")\n",
    "ax.hlines(mean_k_cls, 2, 6, color='b', ls=\":\", label=\"K (cls)\")\n",
    "ax.hlines(mean_v_qm, 2, 6, color='r', ls=\"--\", label=\"V (qm)\")\n",
    "ax.hlines(mean_k_qm, 2, 6, color='b', ls=\"--\", label=\"K (qm)\")\n",
    "ax.set_xlabel(r\"$t$ / ps\"); ax.set_ylabel(r\"energy / a.u.\"); \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compute the RDF. Note the difficulty in converging these with a short simulation: you could get smoother curves by averaging over all beads (they are output so you only need to implement a nested sum) but the typical relaxation time for the O-O correlations is of the order of 10ps, and so longer simulations would really be needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads RDF references from a long-ish Suzuki-Chin run\n",
    "_, rdf_sc_oo, rdf_sc_oh, rdf_sc_hh = np.loadtxt(\"5-gle/ref_rdf_sc.dat\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbins = get_rdf(pos_pg[2][0], rmax=4.5, nbins=200, elements=[8, 8])[1]\n",
    "rdf_pg_oo = {}; rdf_pg_oh = {}; rdf_pg_hh = {}\n",
    "for p in [2,4,6]:\n",
    "    rdf_pg_oo[p] = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 8])[0] for f in pos_pg[p][100::2]]).mean(axis=0)/(1/3)\n",
    "    rdf_pg_oh[p] = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[8, 1])[0] for f in pos_pg[p][100::2]]).mean(axis=0)/(2/3)\n",
    "    rdf_pg_hh[p] = np.asarray([ get_rdf(f, rmax=4.5, nbins=200, elements=[1, 1])[0] for f in pos_pg[p][100::2]]).mean(axis=0)/(2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 6\n",
    "# note that this reuses the classical RDF from section 2\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(rbins, rdf_cls_oo, 'r', ls=\":\" )\n",
    "ax.plot(rbins, rdf_cls_oh, c='gray', ls=\":\" )\n",
    "ax.plot(rbins, rdf_cls_hh, 'c', ls=\":\" )\n",
    "ax.plot(rbins, rdf_sc_oo, 'r', ls=\"--\" )\n",
    "ax.plot(rbins, rdf_sc_hh, 'c', ls=\"--\" )\n",
    "ax.plot(rbins, rdf_sc_oh, c='gray', ls=\"--\" )\n",
    "ax.plot(rbins, rdf_pg_oo[p], 'r', ls=\"-\" )\n",
    "ax.plot(rbins, rdf_pg_oh[p], c='gray', ls=\"-\" )\n",
    "ax.plot(rbins, rdf_pg_hh[p], c='c', ls=\"-\" )\n",
    "ax.set_xlabel(r\"$r / \\AA$\"); ax.set_ylabel(r\"RDF\"); \n",
    "ax.set_ylim(-0.1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue; font-weight:bold\">\n",
    "Compute the quantum corrections to potential and kinetic energy per molecule. Also, plot the RDF of the PIGLET trajectories against those from the \"quantum thermostat\" simulations above. What can you conclude in terms of the shortcomings of QT simulations? You can also compare with the reference PIMD RDF to verify that PIGLET results are indeed closer to the correct quantum fluctuations.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_NB: you will need the results of [Section 3](#non-equilibrium), as well as the reference values defined above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dynamics\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamical properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the velocity-velocity correlation spectrum, that is the Fourier transform of the velocity-velocity correlation function. This has already been introduced in <a href=\"./3-rpmd.ipynb\"> the RPMD module</a> as one of the key indicators of the dynamical properties of a system, being closely connected to the vibrational density of states, and a number of spectroscopic observables. \n",
    "\n",
    "Given that it involves the correlations between the velocities of many particles, we don't compute $c_{vv}$ manually from within this notebook, but use some of the tools that are provided with i-PI. If you have installed i-PI and set the path correctly, you should be able to run it from within the `pimd-mooc/5-gle` folder.\n",
    "We use one of the outputs of the equilibrium GLE runs from [Section 2](#equilibrium), so make sure you have run that section and have not removed the outputs\n",
    "\n",
    "```\n",
    "$ i-pi-getacf -ifile md-gle_smart.vel_0.xyz -mlag 2000 -ftpad 500 -ftwin cosine-blackman \\\n",
    "              -dt \"1.0 femtosecond\" -oprefix cvv-gle_smart\n",
    "```\n",
    "\n",
    "_(either enter the command on a single line, or make sure you escape the carriage return)_. This will generate two files: `cvv-gle_smart_acf.data` contains the correlation function, and `cvv-gle_smart_facf.data` its Fourier transform.  We load it, together from a reference $c_{vv}$ from a reference calculation using a gentle global thermostat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvv_gle = np.loadtxt('5-gle/cvv-gle_smart_facf.data')\n",
    "cvv_svr = np.loadtxt('5-gle/ref_cvv-svr_facf.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the \"smart-sampling\" GLE is rather gentle, it clearly modifies the lineshape of the velocity correlation spectrum, broadening and slightly redshifting the bending and stretching peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "au2cm1 = 219474.63 # frequency axis is given in a.u.\n",
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(au2cm1*cvv_gle[:,0], cvv_gle[:,1], 'r-')\n",
    "ax.plot(au2cm1*cvv_svr[:,0], cvv_svr[:,1], 'gray', ls='--')\n",
    "ax.set_xlim(0,5000); ax.set_xlabel(r\"$\\omega$ / cm$^{-1}$\"); ax.set_ylabel(r\"$c_{vv}$ / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use another tool to apply the Richardson-Lucy deconvolution to the GLE-distorted spectrum, to recover the \"true\" dynamics. See [DOI: 10.1063/1.4990536](https://doi.org/10.1063/1.4990536) for a discussion of the underlying theory. \n",
    "\n",
    "The program needs the velocity correlation spectrum as well as the parameters of the GLE that was used to generate the underlying trajectory. It can extract them from the i-PI input file, if you have kept it\n",
    "\n",
    "```\n",
    "$ i-pi-gleacf -a deconv -ifacf cvv-gle_smart_facf.data -ixml smart.xml -ts 1.0 \\\n",
    "              -op cvv-gle_rl -s 2 -dp 100 10\n",
    "```\n",
    "\n",
    "or from a raw file that you can write containing the matrix [in the appropriate units and raw format](https://gle4md.org/index.html?page=matrix&kind=smart&tslow=5&utslow=ps&smrange=6-3&outmode=raw&aunits=aut)\n",
    "\n",
    "```\n",
    "$ i-pi-gleacf -a deconv -ifacf cvv-gle_smart_facf.data -ia smart_a -ts 1.0 \\\n",
    "              -op cvv-gle_rl -s 2 -dp 100 10\n",
    "```\n",
    "\n",
    "This generates a series of files `cvv-gle_rl_XXX.data`, that correspond to successive iterations of the R-L deconvolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvv_rl = []\n",
    "for i in range(10, 100, 10):\n",
    "    cvv_rl.append(np.loadtxt('5-gle/cvv-gle_rl_%03d.data' % (i)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that iterating R-L too much amplifies noise in the data, so in practice one may want to implement an \"early stop\" criterion based on the balance between the residual error in the forward convolution and some measure of smoothness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(au2cm1*cvv_gle[:,0], cvv_gle[:,1], 'r-')\n",
    "ax.plot(au2cm1*cvv_rl[0][:,0], cvv_rl[0][:,1], c=(0.8,0,0.2))\n",
    "ax.plot(au2cm1*cvv_rl[5][:,0], cvv_rl[5][:,1], c=(0.5,0,0.5))\n",
    "ax.plot(au2cm1*cvv_rl[-1][:,0], cvv_rl[-1][:,1], c=(0.,0,1))\n",
    "ax.plot(au2cm1*cvv_svr[:,0], cvv_svr[:,1], 'gray', ls='--')\n",
    "ax.set_xlim(0,5000); ax.set_xlabel(r\"$\\omega$ / cm$^{-1}$\"); ax.set_ylabel(r\"$c_{vv}$ / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also post-process PIGLET simulations to extract an estimate of the quantum time correlation functions.\n",
    "If you haven't stored the XML input for the simulations in [Section 4](#pi-gle) you may have to re-create the one for $P=6$ before you run this command (that also needs the output of those simulations)\n",
    "\n",
    "```\n",
    "$ i-pi-gleacf -a deconv -ifacf cvv-piglet_6_facf.data -ixml piglet_6.xml -ts 1.0 \\\n",
    "              -op cvv-piglet_rl -s 2 -dp 500 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvv_piglet = np.loadtxt('5-gle/cvv-piglet_6_facf.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvv_piglet_rl = []\n",
    "for i in range(10, 500, 10):\n",
    "    cvv_piglet_rl.append(np.loadtxt('5-gle/cvv-piglet_rl_%03d.data' % (i)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that given the short trajectories and the very aggressive thermostatting associated with the \"OPT-H\" centroid thermostat, it is hard to find a good balance between the level of noise and the progress of deconvolution. Still, one can see clearly the red-shift of the stretch peaks which is one of the hallmarks of quantum dynamical effects in liquid water."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(5,3), constrained_layout=True)\n",
    "ax.plot(au2cm1*cvv_piglet[:,0], cvv_piglet[:,1], 'r-')\n",
    "ax.plot(au2cm1*cvv_piglet_rl[0][:,0], cvv_piglet_rl[0][:,1], c=(0.8,0,0.2))\n",
    "ax.plot(au2cm1*cvv_piglet_rl[5][:,0], cvv_piglet_rl[5][:,1], c=(0.5,0,0.5))\n",
    "ax.plot(au2cm1*cvv_piglet_rl[-1][:,0], cvv_piglet_rl[-1][:,1], c=(0.,0,1))\n",
    "ax.plot(au2cm1*cvv_svr[:,0], cvv_svr[:,1], 'gray', ls='--')\n",
    "ax.set_xlim(0,5000); ax.set_xlabel(r\"$\\omega$ / cm$^{-1}$\"); ax.set_ylabel(r\"$c_{vv}$ / a.u.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Something more:** _You can try to run a longer simulation with the weaker \"OPT-V\" centroid thermostat, obtaining a better-converged and less dramatically broadened initial spectrum. This should give a more stable deconvolution, and a quantum spectrum in very good agreement with more expensive approximate quantum dynamics techniques_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "397px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
